# -*- coding: utf-8 -*-
"""22L-6721-6J-Lab7-Q1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-WsEufeHz7MLdvOyxaWdHa6mDDdXL7Pb
"""

# Make a prediction with weights
def predict(row, weights):
	activation = weights[0]
	for i in range(len(row)-1):
		activation += weights[i + 1] * row[i]
	return 1.0 if activation >= 1 else 0.0

# Estimate Perceptron weights using stochastic gradient descent
def train_weights(dataset, weights, l_rate, n_epoch):
  for epoch in range(n_epoch):
    sum_error = 0.0
    for row in dataset:
      prediction = predict(row, weights)
      error = row[-1] - prediction
      sum_error += error**2
      weights[0] = weights[0] + l_rate * error
      for i in range(len(row)-1):
        weights[i + 1] = weights[i + 1] + l_rate * error * row[i]
    print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))
    if sum_error == 0.0:
      break
  return weights

# and logic gate data set
print("AND Logic")
and_dataset = [[0, 0, 0],
		   [0, 1, 0],
		   [1, 0, 0],
		   [1, 1, 1]]
weights = [-1, 0, 0]
weights = train_weights(and_dataset, weights, 0.1, 10)
print(weights)
for row in and_dataset:
	prediction = predict(row, weights)
	print("Expected=%d, Predicted=%d" % (row[-1], prediction))

# or logic gate data set
print("OR Logic")
or_dataset = [[0, 0, 0],
		   [0, 1, 1],
		   [1, 0, 1],
		   [1, 1, 1]]
weights = [-1, 0, 0]
weights = train_weights(or_dataset, weights, 0.2, 10)
print(weights)
for row in or_dataset:
	prediction = predict(row, weights)
	print("Expected=%d, Predicted=%d" % (row[-1], prediction))